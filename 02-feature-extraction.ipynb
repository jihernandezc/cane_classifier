{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**<h1><center>Análisis de la calidad de trozos de caña de azúcar mediante visión artificial</center></h1>**\n",
    "\n",
    "**<h2><center> Visión Artificial - 2024-2</center></h2>**\n",
    "\n",
    "<center><img src=\"unal.png\" width=\"300\"></center>\n",
    "\n",
    "**<h3> Presentado por: </h3>**\n",
    "<ul>\n",
    "  <li>Juan Esteban Arango Zapata - <a href=\"mailto:juarangoz@unal.edu.co\">juarangoz@unal.edu.co</a> - CC 1018230863</li>\n",
    "  <li>Paulina Hernández Morales - <a href=\"mailto:pauhernandezmo@unal.edu.co\">pauhernandezmo@unal.edu.co</a> - TI 1035420888</li>\n",
    "  <li>Jimena Hernández Castillo - <a href=\"mailto:jihernandezc@unal.edu.co\">jihernandezc@unal.edu.co</a> - TI 1022094340</li>\n",
    "  <li>Juan Camilo López López - <a href=\"mailto:julopezlop@unal.edu.co\">julopezlop@unal.edu.co</a> - CC 1025533050</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h3><center> Extracción de características </h3></center>**\n",
    "\n",
    "**<h4>Importación de librerias:</h4>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "c016b473bf88408c809b7d5425c6d0fd",
    "deepnote_cell_type": "code",
    "execution_context_id": "26cd2d8b-b691-47e0-b173-454a47d7578a",
    "execution_millis": 1519,
    "execution_start": 1740526235331,
    "source_hash": "a940b343"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "73b1ea2eae7a4b93b7d554393837f388",
    "deepnote_cell_type": "code",
    "execution_context_id": "26cd2d8b-b691-47e0-b173-454a47d7578a",
    "execution_millis": 0,
    "execution_start": 1740527732504,
    "source_hash": "d0f8ae6c"
   },
   "outputs": [],
   "source": [
    "def get_simplified_name(path):\n",
    "    \"\"\"\n",
    "    Extrae y simplifica el nombre de la imagen para visualización.\n",
    "    Convierte algo como \"/work/segmentaciones_aplicadas/Damaged_KMeans_fondo_negro.png\"\n",
    "    a \"Damaged (KMeans)\"\n",
    "    \"\"\"\n",
    "    file_name = Path(path).name  # Obtiene solo el nombre del archivo sin la ruta\n",
    "    parts = file_name.split('_')\n",
    "    \n",
    "    if len(parts) >= 2:\n",
    "        category = parts[0]  # Damaged, Healthy, Mutilated\n",
    "        method = parts[1]    # KMeans, Otsu\n",
    "        return f\"{category} ({method})\"\n",
    "    else:\n",
    "        # Fallback si el formato no coincide\n",
    "        return Path(path).stem\n",
    "\n",
    "\n",
    "class CustomKeypointDetector:\n",
    "    def __init__(self):\n",
    "        self.patch_size = 16  # Tamaño de la región alrededor del punto clave\n",
    "        self.threshold = 0.01  # Umbral para detección de puntos\n",
    "        \n",
    "    def detect_keypoints(self, image):\n",
    "        \"\"\"\n",
    "        Detecta puntos clave usando una combinación de métodos\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "        \n",
    "        # 1. Detectar esquinas usando una versión modificada del método de Harris\n",
    "        dx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "        dy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "        \n",
    "        Ixx = gaussian_filter(dx**2, sigma=2)\n",
    "        Iyy = gaussian_filter(dy**2, sigma=2)\n",
    "        Ixy = gaussian_filter(dx*dy, sigma=2)\n",
    "        \n",
    "        # Calcular la respuesta de Harris\n",
    "        det = Ixx * Iyy - Ixy**2\n",
    "        trace = Ixx + Iyy\n",
    "        response = det - 0.05 * (trace**2)\n",
    "        \n",
    "        # Encontrar máximos locales\n",
    "        keypoints = []\n",
    "        pad = self.patch_size // 2\n",
    "        \n",
    "        for y in range(pad, gray.shape[0] - pad):\n",
    "            for x in range(pad, gray.shape[1] - pad):\n",
    "                if response[y, x] > self.threshold:\n",
    "                    # Verificar si es máximo local en una ventana 3x3\n",
    "                    window = response[y-1:y+2, x-1:x+2]\n",
    "                    if response[y, x] == np.max(window):\n",
    "                        keypoints.append((x, y))\n",
    "        \n",
    "        return keypoints\n",
    "    \n",
    "    def compute_descriptors(self, image, keypoints):\n",
    "        \"\"\"\n",
    "        Calcula descriptores para cada punto clave\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        descriptors = []\n",
    "        \n",
    "        for x, y in keypoints:\n",
    "            # Extraer parche alrededor del punto clave\n",
    "            patch = gray[y-self.patch_size//2:y+self.patch_size//2,\n",
    "                        x-self.patch_size//2:x+self.patch_size//2]\n",
    "            \n",
    "            # 1. Gradientes\n",
    "            dx = cv2.Sobel(patch, cv2.CV_32F, 1, 0, ksize=3)\n",
    "            dy = cv2.Sobel(patch, cv2.CV_32F, 0, 1, ksize=3)\n",
    "            \n",
    "            # Magnitud y orientación de gradientes\n",
    "            magnitude = np.sqrt(dx**2 + dy**2)\n",
    "            orientation = np.arctan2(dy, dx)\n",
    "            \n",
    "            # 2. Histograma de gradientes\n",
    "            hist_grad = np.histogram(orientation.flatten(), bins=8, \n",
    "                                   weights=magnitude.flatten(), range=(-np.pi, np.pi))[0]\n",
    "            \n",
    "            # 3. Estadísticas locales\n",
    "            mean_intensity = np.mean(patch)\n",
    "            std_intensity = np.std(patch)\n",
    "            \n",
    "            # 4. Patrones de intensidad\n",
    "            threshold = np.mean(patch)\n",
    "            binary_pattern = (patch > threshold).astype(np.float32)\n",
    "            pattern_features = np.mean(binary_pattern, axis=1)  # Promedio por filas\n",
    "            \n",
    "            # Combinar todas las características en un descriptor\n",
    "            descriptor = np.concatenate([\n",
    "                hist_grad / np.sum(hist_grad),  # Normalizado\n",
    "                [mean_intensity / 255, std_intensity / 255],  # Normalizados\n",
    "                pattern_features\n",
    "            ])\n",
    "            \n",
    "            descriptors.append(descriptor)\n",
    "            \n",
    "        return np.array(descriptors)\n",
    "\n",
    "def process_sugarcane_images(image_paths):\n",
    "    \"\"\"\n",
    "    Procesa múltiples imágenes de caña y extrae sus puntos clave y descriptores\n",
    "    \"\"\"\n",
    "    detector = CustomKeypointDetector()\n",
    "    results = {}\n",
    "    \n",
    "    for path in image_paths:\n",
    "        # Leer imagen\n",
    "        image = cv2.imread(path)\n",
    "        if image is None:\n",
    "            print(f\"No se pudo leer la imagen: {path}\")\n",
    "            continue\n",
    "            \n",
    "        # Detectar puntos clave\n",
    "        keypoints = detector.detect_keypoints(image)\n",
    "        \n",
    "        # Calcular descriptores\n",
    "        descriptors = detector.compute_descriptors(image, keypoints)\n",
    "        \n",
    "        results[path] = {\n",
    "            'image': image,\n",
    "            'keypoints': keypoints,\n",
    "            'descriptors': descriptors,\n",
    "            'num_keypoints': len(keypoints)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nResultados para {path}:\")\n",
    "        print(f\"Número de puntos clave encontrados: {len(keypoints)}\")\n",
    "        print(f\"Dimensión de los descriptores: {descriptors.shape}\")\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ac6ab80fb5b94dc4935a9cbc2fd0bccc",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "# Documentación del Código de Extracción de Características en Imágenes de Caa de Azúcar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d21c01ccaecb4228956e0d0c9d866503",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### CustomKeypointDetector (Clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "57c876e5922a4cc0a3e3ba9a25228e14",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Esta clase implementa un detector de puntos clave personalizado basado en métodos de detección de esquinas y características de textura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7cf18d67f18a42d294ac71809d0f778d",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Atributos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a2d41bbb297d439694b60b3323f5c2a8",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `patch_size` (int): Tamaño de la región alrededor del punto clave (16 por defecto).\n",
    "- `threshold` (float): Umbral para la detección de puntos clave (0.01 por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "15ea769dff4c4ed28bac7fac15bf7624",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Métodos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f1560aa31f86459395e7fe6cda993c52",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "-`detect_keypoints(image)`\n",
    "Detecta puntos clave en la imagen utilizando un detector basado en Harris modificado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7084c142100442bf8645b45acf2ceee2",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "968d23ecfcad47dd86bb7c7407cae3dd",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `image` (numpy.ndarray): Imagen de entrada en formato BGR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3ad009a658144b4a9a22d1052c0397a4",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Proceso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8e2110bf621b44b78a301a34440da581",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "1. Convierte la imagen a escala de grises y la convierte a `float32`.\n",
    "2. Calcula los gradientes `dx` y `dy` usando el operador Sobel.\n",
    "3. Aplica un filtro gaussiano para suavizar los productos de gradientes.\n",
    "4. Calcula la respuesta de Harris.\n",
    "5. Encuentra máximos locales en una ventana 3x3 y almacena las coordenadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5c35231739a644e5b41f1f5147001f76",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Retorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ef0b1d859cf4d2eb231fd937a47edab",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `list`: Lista de coordenadas de los puntos clave encontrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "98b38208983541ebae1125b5dc66f8a2",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Compute_descriptors(image, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9317ebb61ac4421ea825d004bdbd2721",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Calcula los descriptores de los puntos clave detectados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "28f6f354cd004f91b58ab72dbfda8ed9",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7ddb6131520249af97bfbcd31a17fd0e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `image` (numpy.ndarray): Imagen en formato BGR.\n",
    "- `keypoints` (list): Lista de puntos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1399dd95b2f44cbc8fc50a113649d48a",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Proceso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4d522993cd38474ea7f188e70a11ca98",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "1. Convierte la imagen a escala de grises.\n",
    "2. Extrae un parche alrededor de cada punto clave.\n",
    "3. Calcula los gradientes en el parche.\n",
    "4. Obtiene la magnitud y orientación de los gradientes.\n",
    "5. Genera un histograma de gradientes.\n",
    "6. Calcula estadísticas locales como la media y desviación estándar.\n",
    "7. Genera un patrón binario de intensidades.\n",
    "8. Combina todas las características en un vector descriptor normalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "89c7333e06a7411493f18d2767dd8c83",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Retorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "07d8315d00f448efa10699242918e33b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `numpy.ndarray`: Matriz de descriptores de los puntos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8d48f6e90ef04f9e99c738a505d8f16e",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### process_surcane_images(images_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "046865e1b3214d45b363a622a9dd4286",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Descripción:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1d36d7e53dc845498f08f2c6844dc349",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Procesa múltiples imágenes de caña de azúcar y extrae sus puntos clave y descriptores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "51799afb768946a391f94d3985c09120",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2396503c22a24502bf1d32692ad570f5",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `image_paths` (list): Lista de rutas de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b7ed5f89a2c48e98bc917464c662703",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Proceso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "840fc60f6fb142a08b334447b481dc45",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "1. Crea una instancia de `CustomKeypointDetector`.\n",
    "2. Itera sobre cada imagen:\n",
    "   - Carga la imagen.\n",
    "   - Detecta los puntos clave.\n",
    "   - Calcula los descriptores.\n",
    "   - Almacena los resultados en un diccionario.\n",
    "   - Imprime información sobre el número de puntos clave y la dimensión de los descriptores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c5db28cd2cdf430c9eee815cf235a76b",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Retorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b1fadc72ac2d491ba40dd07a787c9f4a",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `dict`: Diccionario con información de las imágenes procesadas:\n",
    "  - `image`: Imagen original.\n",
    "  - `keypoints`: Lista de puntos clave.\n",
    "  - `descriptors`: Matriz de descriptores.\n",
    "  - `num_keypoints`: Cantidad de puntos clave detectados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8c35e1a63669463eb3e463ad7d5487c5",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    " - `path` (str): Ruta del archivo de imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "59ae409974da454c9e3031c66556628c",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Retorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f64b84feb77c4e409538c6f2db002428",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `str`: Nombre simplificado de la imagen en formato \"Categoría (Método)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ec5635eeeb9b4616b6263de01c261213",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### CustomKeypointDetector (clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "10a5663770d6422a9e1dbfff3abacf06",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Esta clase implementa un detector de puntos clave personalizado basado en métodos de detección de esquinas y características de textura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1d9acdd5f01f4a61a68bcfaffb4cd665",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9268c71d46f44e10b086df2fb74d8fc4",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `patch_size` (int): Tamaño de la región alrededor del punto clave (16 por defecto).\n",
    "- `threshold` (float): Umbral para la detección de puntos clave (0.01 por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "142a9c3f4418499cbb8fd39ac5bccd7c",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Métodos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c1c78d9d4a144df09064d367a40f15e2",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### detect_keypoints(image):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0aa542cfe4dd43b89b62b89c8e01785c",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Detecta puntos clave en la imagen utilizando un detector basado en Harris modificado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ea8c648b990b469fb3105cbbe20c1a26",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Parámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "77ab6af5c4af48728b2f32724611628d",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "\n",
    "- `image` (numpy.ndarray): Imagen de entrada en formato BGR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "de170ef69c674df8b87c9a7be5ae84d2",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Proceso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ee995c168f3544d69a223ea4aec17b3c",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "1. Convierte la imagen a escala de grises y la convierte a `float32`.\n",
    "2. Calcula los gradientes `dx` y `dy` usando el operador Sobel.\n",
    "3. Aplica un filtro gaussiano para suavizar los productos de gradientes.\n",
    "4. Calcula la respuesta de Harris.\n",
    "5. Encuentra máximos locales en una ventana 3x3 y almacena las coordenadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "947a2bb36eb043d1a4994dca670bf82e",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Retorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "30b3b10eae3b4c2c91804cbb3977e205",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `list`: Lista de coordenadas de los puntos clave encontrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "db41fbb587294390b6843ad4f170509a",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### compute_descriptors(image,keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "90274f90fa5a4fad8c9cc0c0dacc0d26",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Calcula los descriptores de los puntos clave detectados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "89706a65ec39406c9f7baa99c0fd2f07",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f2657165ff9440ce9e873d31f824b4a6",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `image` (numpy.ndarray): Imagen en formato BGR.\n",
    "- `keypoints` (list): Lista de puntos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4e653fa9bfe64f308cbd14cbdb562094",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Proceso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2dd27dd98f3e40d1b2a499d92fa73c07",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "1. Convierte la imagen a escala de grises.\n",
    "2. Extrae un parche alrededor de cada punto clave.\n",
    "3. Calcula los gradientes en el parche.\n",
    "4. Obtiene la magnitud y orientación de los gradientes.\n",
    "5. Genera un histograma de gradientes.\n",
    "6. Calcula estadísticas locales como la media y desviación estándar.\n",
    "7. Genera un patrón binario de intensidades.\n",
    "8. Combina todas las características en un vector descriptor normalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0609eb914cf04fccacf7978a2d9f7c40",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Retorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dccf32d5192044c19fc1dab454280976",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `numpy.ndarray`: Matriz de descriptores de los puntos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9f470772bf934167b515bc9496dd4eb3",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Process_surcane_images(images_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b1f92fa337b6478dbfa48cab5d150714",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Descripción:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c108d6885f354ea586e5e0d0b78e388a",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Procesa múltiples imágenes de caña de azúcar y extrae sus puntos clave y descriptores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dbb0db3382fd4949a580ddd60e3357ae",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Parámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4135683da0dd491b9a9027904706f1d8",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- `image_paths` (list): Lista de rutas de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8fa33282454344aeabb580d61a34159f",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Proceso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ee66a3397b8a4ebea07fc8347e0f6934",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "1. Crea una instancia de `CustomKeypointDetector`.\n",
    "2. Itera sobre cada imagen:\n",
    "   - Carga la imagen.\n",
    "   - Detecta los puntos clave.\n",
    "   - Calcula los descriptores.\n",
    "   - Almacena los resultados en un diccionario.\n",
    "   - Imprime información sobre el número de puntos clave y la dimensión de los descriptores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "49fef8fa98a945e3aa0ab273193fc015",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Retorno:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5e2342ab56d749399413d499a06bb166",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "\n",
    "- `dict`: Diccionario con información de las imágenes procesadas:\n",
    "  - `image`: Imagen original.\n",
    "  - `keypoints`: Lista de puntos clave.\n",
    "  - `descriptors`: Matriz de descriptores.\n",
    "  - `num_keypoints`: Cantidad de puntos clave detectados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bd8f2f6a94cc43dfaa43a87c7da072b1",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "b6d65f43be214ac188d9e12d6e163722",
    "deepnote_cell_type": "code",
    "execution_context_id": "26cd2d8b-b691-47e0-b173-454a47d7578a",
    "execution_millis": 73319,
    "execution_start": 1740527749683,
    "source_hash": "b2b61929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo leer la imagen: /work/segmentaciones_aplicadas/Damaged_KMeans_fondo_negro.png\n",
      "No se pudo leer la imagen: /work/segmentaciones_aplicadas/Damaged_Otsu_fondo_negro.png\n",
      "No se pudo leer la imagen: /work/segmentaciones_aplicadas/Healthy_KMeans_fondo_negro.png\n",
      "No se pudo leer la imagen: /work/segmentaciones_aplicadas/Healthy_Otsu_fondo_negro.png\n",
      "No se pudo leer la imagen: /work/segmentaciones_aplicadas/Mutilated_KMeans_fondo_negro.png\n",
      "No se pudo leer la imagen: /work/segmentaciones_aplicadas/Mutilated_Otsu_fondo_negro.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 405\u001b[0m\n\u001b[0;32m    402\u001b[0m results \u001b[38;5;241m=\u001b[39m process_sugarcane_images(image_paths)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# Generar visualizaciones y análisis\u001b[39;00m\n\u001b[1;32m--> 405\u001b[0m density_map_fig, analysis_fig, distribution_fig, summary \u001b[38;5;241m=\u001b[39m \u001b[43mvisualize_large_sugarcane_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# Mostrar las figuras (opcional, ya que también se guardan como archivos)\u001b[39;00m\n\u001b[0;32m    408\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[4], line 363\u001b[0m, in \u001b[0;36mvisualize_large_sugarcane_analysis\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m    360\u001b[0m results \u001b[38;5;241m=\u001b[39m prepare_results_for_visualization(results)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Visualización 1: Mapas de densidad en lugar de puntos individuales\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m density_map_fig \u001b[38;5;241m=\u001b[39m \u001b[43mvisualize_density_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m# Visualización 2: Análisis de descriptores optimizado\u001b[39;00m\n\u001b[0;32m    366\u001b[0m analysis_fig, df \u001b[38;5;241m=\u001b[39m analyze_descriptors_improved(results)\n",
      "Cell \u001b[1;32mIn[4], line 57\u001b[0m, in \u001b[0;36mvisualize_density_map\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m     54\u001b[0m num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results)\n\u001b[0;32m     55\u001b[0m rows \u001b[38;5;241m=\u001b[39m (num_images \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Redondeo hacia arriba\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m axes \u001b[38;5;241m=\u001b[39m axes\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (path, data) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results\u001b[38;5;241m.\u001b[39mitems()):\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\tf_env\\lib\\site-packages\\matplotlib\\pyplot.py:1760\u001b[0m, in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;124;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[0;32m   1617\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \n\u001b[0;32m   1758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m fig \u001b[38;5;241m=\u001b[39m figure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw)\n\u001b[1;32m-> 1760\u001b[0m axs \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\tf_env\\lib\\site-packages\\matplotlib\\figure.py:860\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must not be defined both as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    857\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter and as key in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridspec_kw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    858\u001b[0m     gridspec_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m width_ratios\n\u001b[1;32m--> 860\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gridspec(nrows, ncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgridspec_kw)\n\u001b[0;32m    861\u001b[0m axs \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39msubplots(sharex\u001b[38;5;241m=\u001b[39msharex, sharey\u001b[38;5;241m=\u001b[39msharey, squeeze\u001b[38;5;241m=\u001b[39msqueeze,\n\u001b[0;32m    862\u001b[0m                   subplot_kw\u001b[38;5;241m=\u001b[39msubplot_kw)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\tf_env\\lib\\site-packages\\matplotlib\\figure.py:1538\u001b[0m, in \u001b[0;36mFigureBase.add_gridspec\u001b[1;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;124;03mLow-level API for creating a `.GridSpec` that has this figure as a parent.\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pop in case user has added this...\u001b[39;00m\n\u001b[1;32m-> 1538\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSpec(nrows\u001b[38;5;241m=\u001b[39mnrows, ncols\u001b[38;5;241m=\u001b[39mncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gs\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\tf_env\\lib\\site-packages\\matplotlib\\gridspec.py:363\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[1;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhspace \u001b[38;5;241m=\u001b[39m hspace\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;241m=\u001b[39m figure\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\anaconda3\\envs\\tf_env\\lib\\site-packages\\matplotlib\\gridspec.py:48\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[1;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    If not given, all rows will have the same height.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nrows, Integral) \u001b[38;5;129;01mor\u001b[39;00m nrows \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ncols, Integral) \u001b[38;5;129;01mor\u001b[39;00m ncols \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncols\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of rows must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# En visualize_keypoints_sampled\n",
    "def visualize_keypoints_sampled(results, max_points=1000):\n",
    "    \"\"\"\n",
    "    Visualiza una muestra aleatoria de los puntos clave detectados en cada imagen\n",
    "    \"\"\"\n",
    "    # Determinar el número de imágenes y ajustar el tamaño de la cuadrícula\n",
    "    num_images = len(results)\n",
    "    rows = (num_images + 2) // 3  # Redondeo hacia arriba para tener suficientes filas\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, 5*rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (path, data) in enumerate(results.items()):\n",
    "        image = data['image']\n",
    "        keypoints = data['keypoints']\n",
    "        \n",
    "        # Tomar una muestra aleatoria si hay demasiados puntos\n",
    "        if len(keypoints) > max_points:\n",
    "            sampled_keypoints = random.sample(keypoints, max_points)\n",
    "        else:\n",
    "            sampled_keypoints = keypoints\n",
    "        \n",
    "        # Convertir de BGR (OpenCV) a RGB (Matplotlib)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Mostrar la imagen\n",
    "        axes[i].imshow(image_rgb)\n",
    "        \n",
    "        # Dibujar puntos clave (muestra)\n",
    "        for x, y in sampled_keypoints:\n",
    "            axes[i].plot(x, y, 'ro', markersize=1, alpha=0.7)\n",
    "            \n",
    "        # Título con nombre simplificado\n",
    "        simple_name = get_simplified_name(path)\n",
    "        if len(keypoints) > max_points:\n",
    "            axes[i].set_title(f\"{simple_name}: {len(keypoints)} puntos (mostrando {max_points})\")\n",
    "        else:\n",
    "            axes[i].set_title(f\"{simple_name}: {len(keypoints)} puntos\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Ocultar ejes vacíos si hay menos de rows*3 imágenes\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def visualize_density_map(results):\n",
    "    \"\"\"\n",
    "    Crea mapas de densidad para cada imagen en lugar de mostrar puntos individuales\n",
    "    \"\"\"\n",
    "    # Determinar el número de imágenes y ajustar el tamaño de la cuadrícula\n",
    "    num_images = len(results)\n",
    "    rows = (num_images + 2) // 3  # Redondeo hacia arriba\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, 5*rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (path, data) in enumerate(results.items()):\n",
    "        image = data['image']\n",
    "        keypoints = data['keypoints']\n",
    "        \n",
    "        # Crear mapa de densidad\n",
    "        h, w = image.shape[:2]\n",
    "        density_map = np.zeros((h, w))\n",
    "        \n",
    "        for x, y in keypoints:\n",
    "            # Comprobar límites\n",
    "            if 0 <= x < w and 0 <= y < h:\n",
    "                density_map[int(y), int(x)] += 1\n",
    "        \n",
    "        # Aplicar filtro gaussiano para suavizar\n",
    "        density_map = gaussian_filter(density_map, sigma=10)\n",
    "        \n",
    "        # Normalizar para visualización\n",
    "        if np.max(density_map) > 0:\n",
    "            density_map = density_map / np.max(density_map)\n",
    "        \n",
    "        # Mostrar la imagen original\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(image_rgb)\n",
    "        \n",
    "        # Superponer el mapa de densidad\n",
    "        axes[i].imshow(density_map, alpha=0.5, cmap='hot')\n",
    "        \n",
    "        # Título con nombre simplificado\n",
    "        simple_name = get_simplified_name(path)\n",
    "        axes[i].set_title(f\"{simple_name}: {len(keypoints)} puntos\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Ocultar ejes vacíos\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_descriptors_improved(results):\n",
    "    \"\"\"\n",
    "    Analiza los descriptores y crea visualizaciones para comparar categorías\n",
    "    Optimizado para manejar grandes cantidades de puntos\n",
    "    \"\"\"\n",
    "    # Crear un DataFrame para análisis\n",
    "    data = []\n",
    "    for path, result in results.items():\n",
    "        # Usar la nueva función para obtener nombres simplificados\n",
    "        simple_name = get_simplified_name(path)\n",
    "        \n",
    "        # Extraer solo la categoría (Damaged, Healthy, Mutilated)\n",
    "        category = simple_name.split()[0]\n",
    "        \n",
    "        # Características básicas\n",
    "        num_keypoints = result['num_keypoints']\n",
    "        \n",
    "        # Características de los descriptores - usar muestreo para grandes cantidades\n",
    "        descriptors = result['descriptors']\n",
    "        if len(descriptors) > 0:\n",
    "            # Si hay muchos descriptores, tomar una muestra aleatoria\n",
    "            if len(descriptors) > 10000:\n",
    "                sample_indices = random.sample(range(len(descriptors)), 10000)\n",
    "                descriptor_sample = descriptors[sample_indices]\n",
    "            else:\n",
    "                descriptor_sample = descriptors\n",
    "                \n",
    "            # Calcular métricas sobre la muestra\n",
    "            avg_descriptor = np.mean(descriptor_sample, axis=0)\n",
    "            \n",
    "            # Dividir el descriptor en secciones lógicas según tu implementación\n",
    "            # Ajusta estos índices según la estructura real de tus descriptores\n",
    "            descriptor_size = avg_descriptor.shape[0]\n",
    "            \n",
    "            # Calcular estadísticas basadas en la estructura detectada\n",
    "            if descriptor_size >= 26:  # Si coincide con el tamaño mencionado\n",
    "                # Asumiendo la estructura: primeros 8 son histograma, luego 2 son estadísticas, resto son patrones\n",
    "                avg_gradient_hist = np.mean(avg_descriptor[:8])\n",
    "                avg_intensity = avg_descriptor[8]\n",
    "                avg_std = avg_descriptor[9]\n",
    "                avg_pattern = np.mean(avg_descriptor[10:])\n",
    "            else:\n",
    "                # Si la estructura es diferente, hacer una división genérica\n",
    "                third = descriptor_size // 3\n",
    "                avg_gradient_hist = np.mean(avg_descriptor[:third])\n",
    "                avg_intensity = np.mean(avg_descriptor[third:2*third])\n",
    "                avg_std = np.std(avg_descriptor)\n",
    "                avg_pattern = np.mean(avg_descriptor[2*third:])\n",
    "        else:\n",
    "            avg_gradient_hist = 0\n",
    "            avg_intensity = 0\n",
    "            avg_std = 0\n",
    "            avg_pattern = 0\n",
    "        \n",
    "        # No usamos keypoints_with_response ya que no está en tus datos originales\n",
    "        # En su lugar, usamos alguna métrica derivada de los descriptores\n",
    "        avg_response = avg_std  # Como ejemplo, usamos la desviación estándar como \"respuesta\"\n",
    "            \n",
    "        data.append({\n",
    "            'category': category,\n",
    "            'image': simple_name,  # Usar el nombre simplificado\n",
    "            'num_keypoints': num_keypoints,\n",
    "            'keypoints_per_pixel': num_keypoints / (result['image'].shape[0] * result['image'].shape[1]),\n",
    "            'avg_gradient_hist': avg_gradient_hist,\n",
    "            'avg_intensity': avg_intensity,\n",
    "            'avg_std': avg_std,\n",
    "            'avg_pattern': avg_pattern,\n",
    "            'avg_response': avg_response\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Crear múltiples visualizaciones\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Número de puntos clave por categoría\n",
    "    sns.barplot(x='category', y='num_keypoints', data=df, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Número de puntos clave por categoría')\n",
    "    axes[0, 0].set_xlabel('Categoría')\n",
    "    axes[0, 0].set_ylabel('Número de puntos clave')\n",
    "    \n",
    "    # Ajustar formato para números grandes\n",
    "    ylim = axes[0, 0].get_ylim()\n",
    "    axes[0, 0].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "    \n",
    "    # 2. Densidad de puntos clave por píxel\n",
    "    sns.barplot(x='category', y='keypoints_per_pixel', data=df, ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Densidad de puntos clave (puntos/píxel)')\n",
    "    axes[0, 1].set_xlabel('Categoría')\n",
    "    axes[0, 1].set_ylabel('Puntos por píxel')\n",
    "    \n",
    "    # 3. Comparación de características entre categorías\n",
    "    features = ['avg_gradient_hist', 'avg_intensity', 'avg_std', 'avg_pattern']\n",
    "    feature_df = df.groupby('category')[features].mean().reset_index()\n",
    "    feature_df_melted = pd.melt(feature_df, id_vars=['category'], value_vars=features, \n",
    "                              var_name='Característica', value_name='Valor')\n",
    "    \n",
    "    sns.barplot(x='category', y='Valor', hue='Característica', data=feature_df_melted, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Características promedio por categoría')\n",
    "    axes[1, 0].set_xlabel('Categoría')\n",
    "    axes[1, 0].set_ylabel('Valor promedio')\n",
    "    axes[1, 0].legend(title='Característica')\n",
    "    \n",
    "    # 4. Número de puntos vs Desviación estándar\n",
    "    sns.scatterplot(x='num_keypoints', y='avg_std', hue='category', size='avg_intensity', \n",
    "                  sizes=(50, 200), data=df, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Relación entre número de puntos y desviación estándar')\n",
    "    axes[1, 1].set_xlabel('Número de puntos clave')\n",
    "    axes[1, 1].set_ylabel('Desviación estándar promedio')\n",
    "    axes[1, 1].ticklabel_format(style='scientific', axis='x', scilimits=(0,0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, df\n",
    "\n",
    "def create_distribution_visualization_optimized(results):\n",
    "    \"\"\"\n",
    "    Crea una visualización de la distribución espacial de los puntos clave\n",
    "    Optimizado para manejar grandes cantidades de puntos\n",
    "    \"\"\"\n",
    "    # Obtener categorías (usando los nombres simplificados)\n",
    "    categories = set()\n",
    "    for path in results.keys():\n",
    "        category = get_simplified_name(path).split()[0]  # Extraer solo la parte de la categoría\n",
    "        categories.add(category)\n",
    "    \n",
    "    num_categories = len(categories)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_categories, figsize=(6*num_categories, 6))\n",
    "    if num_categories == 1:\n",
    "        axes = [axes]  # Convertir a lista si solo hay una categoría\n",
    "    \n",
    "    # Agrupar los resultados por categoría\n",
    "    categories_data = {}\n",
    "    for path, data in results.items():\n",
    "        category = get_simplified_name(path).split()[0]  # Extraer solo la parte de la categoría\n",
    "        if category not in categories_data:\n",
    "            categories_data[category] = []\n",
    "        categories_data[category].append(data)\n",
    "    \n",
    "    for i, (category, category_data) in enumerate(sorted(categories_data.items())):\n",
    "        # Crear una imagen de \"mapa de calor\" para cada categoría\n",
    "        # Resolución más baja para mejor rendimiento\n",
    "        resolution = 300\n",
    "        heatmap = np.zeros((resolution, resolution))\n",
    "        \n",
    "        total_points = 0\n",
    "        \n",
    "        for data in category_data:\n",
    "            image = data['image']\n",
    "            keypoints = data['keypoints']\n",
    "            \n",
    "            # Tomar una muestra si hay demasiados puntos\n",
    "            if len(keypoints) > 10000:\n",
    "                sampled_keypoints = random.sample(keypoints, 10000)\n",
    "            else:\n",
    "                sampled_keypoints = keypoints\n",
    "            \n",
    "            # Normalizar las coordenadas\n",
    "            h, w = image.shape[:2]\n",
    "            for x, y in sampled_keypoints:\n",
    "                # Convertir coordenadas de la imagen original a nuestra heatmap\n",
    "                x_norm = int(x * resolution / w)\n",
    "                y_norm = int(y * resolution / h)\n",
    "                \n",
    "                # Asegurar que estamos dentro de los límites\n",
    "                if 0 <= x_norm < resolution and 0 <= y_norm < resolution:\n",
    "                    heatmap[y_norm, x_norm] += 1\n",
    "                    total_points += 1\n",
    "        \n",
    "        # Aplicar filtro gaussiano para suavizar\n",
    "        heatmap = gaussian_filter(heatmap, sigma=5)\n",
    "        \n",
    "        # Normalizar para visualización si hay puntos\n",
    "        if total_points > 0:\n",
    "            heatmap = heatmap / np.max(heatmap)\n",
    "        \n",
    "        # Crear un mapa de colores personalizado\n",
    "        colors = [(0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 0), (1, 0, 0)]\n",
    "        cmap_name = f'custom_{category}'\n",
    "        cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "        \n",
    "        # Mostrar el mapa de calor\n",
    "        im = axes[i].imshow(heatmap, cmap=cm)\n",
    "        axes[i].set_title(f'Distribución de puntos - {category}')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Añadir barra de color\n",
    "        cbar = plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Densidad normalizada')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def generate_summary_report_large(df):\n",
    "    \"\"\"\n",
    "    Genera un informe resumido de los resultados\n",
    "    Adaptado para datasets grandes\n",
    "    \"\"\"\n",
    "    summary = df.groupby('category').agg({\n",
    "        'num_keypoints': ['mean', 'std', 'min', 'max', 'sum'],\n",
    "        'keypoints_per_pixel': ['mean', 'max'],\n",
    "        'avg_intensity': 'mean',\n",
    "        'avg_std': 'mean'\n",
    "    })\n",
    "    \n",
    "    # Formatear para mejor visualización\n",
    "    summary_flat = pd.DataFrame({\n",
    "        'Categoría': summary.index,\n",
    "        'Puntos Promedio': summary['num_keypoints']['mean'].round(2),\n",
    "        'Desviación Estándar': summary['num_keypoints']['std'].round(2),\n",
    "        'Mínimo': summary['num_keypoints']['min'].astype(int),\n",
    "        'Máximo': summary['num_keypoints']['max'].astype(int),\n",
    "        'Total Puntos': summary['num_keypoints']['sum'].astype(int),\n",
    "        'Densidad Promedio': summary['keypoints_per_pixel']['mean'].round(6),\n",
    "        'Intensidad Promedio': summary['avg_intensity']['mean'].round(4),\n",
    "        'Variación Promedio': summary['avg_std']['mean'].round(4)\n",
    "    })\n",
    "    \n",
    "    return summary_flat\n",
    "\n",
    "def prepare_results_for_visualization(results_dict):\n",
    "    \"\"\"\n",
    "    Prepara los resultados para visualización asegurando que tengan el formato correcto\n",
    "    \"\"\"\n",
    "    for path, data in results_dict.items():\n",
    "        # Asegurarse de que tenemos la imagen\n",
    "        if 'image' not in data:\n",
    "            print(f\"Advertencia: La imagen para {path} no está disponible.\")\n",
    "            # Intentar cargar la imagen si la ruta existe\n",
    "            image = cv2.imread(path)\n",
    "            if image is not None:\n",
    "                data['image'] = image\n",
    "            else:\n",
    "                # Crear una imagen en blanco como fallback\n",
    "                data['image'] = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Asegurar que tenemos num_keypoints\n",
    "        if 'num_keypoints' not in data:\n",
    "            data['num_keypoints'] = len(data['keypoints'])\n",
    "            \n",
    "        # Asegurar que tenemos keypoints en el formato correcto\n",
    "        if isinstance(data['keypoints'], np.ndarray):\n",
    "            # Convertir array numpy a lista de tuplas\n",
    "            data['keypoints'] = [(int(kp[0]), int(kp[1])) for kp in data['keypoints']]\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "# Función principal para generar todas las visualizaciones\n",
    "def visualize_large_sugarcane_analysis(results):\n",
    "    \"\"\"\n",
    "    Genera y guarda todas las visualizaciones para el análisis de imágenes de caña\n",
    "    Optimizado para conjuntos de datos con gran cantidad de puntos clave\n",
    "    \n",
    "    Args:\n",
    "        results: Diccionario con los resultados del análisis\n",
    "                \n",
    "    Returns:\n",
    "        Tupla con (density_map_fig, analysis_fig, distribution_fig, summary_df)\n",
    "    \"\"\"\n",
    "    # Preparar resultados para visualización\n",
    "    results = prepare_results_for_visualization(results)\n",
    "    \n",
    "    # Visualización 1: Mapas de densidad en lugar de puntos individuales\n",
    "    density_map_fig = visualize_density_map(results)\n",
    "    \n",
    "    # Visualización 2: Análisis de descriptores optimizado\n",
    "    analysis_fig, df = analyze_descriptors_improved(results)\n",
    "    \n",
    "    # Visualización 3: Mapa de distribución espacial optimizado\n",
    "    distribution_fig = create_distribution_visualization_optimized(results)\n",
    "    \n",
    "    # Generar informe resumido\n",
    "    summary = generate_summary_report_large(df)\n",
    "    \n",
    "    # Guardar figuras\n",
    "    density_map_fig.savefig(\"keypoints_density_map.png\", dpi=300, bbox_inches='tight')\n",
    "    analysis_fig.savefig(\"features_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    distribution_fig.savefig(\"spatial_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(\"\\n===== RESUMEN ESTADÍSTICO POR CATEGORÍA =====\")\n",
    "    print(summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nVisualizaciones guardadas como:\")\n",
    "    print(\"- keypoints_density_map.png\")\n",
    "    print(\"- features_analysis.png\")\n",
    "    print(\"- spatial_distribution.png\")\n",
    "    \n",
    "    return density_map_fig, analysis_fig, distribution_fig, summary\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Lista de imágenes a procesar\n",
    "    image_paths = [\n",
    "        \"/work/segmentaciones_aplicadas/Damaged_KMeans_fondo_negro.png\",\n",
    "        \"/work/segmentaciones_aplicadas/Damaged_Otsu_fondo_negro.png\",\n",
    "        \"/work/segmentaciones_aplicadas/Healthy_KMeans_fondo_negro.png\",\n",
    "        \"/work/segmentaciones_aplicadas/Healthy_Otsu_fondo_negro.png\",\n",
    "        \"/work/segmentaciones_aplicadas/Mutilated_KMeans_fondo_negro.png\",\n",
    "        \"/work/segmentaciones_aplicadas/Mutilated_Otsu_fondo_negro.png\"\n",
    "        # Añade aquí las rutas de las otras imágenes\n",
    "    ]\n",
    "    # Procesar las imágenes y obtener puntos clave y descriptores\n",
    "    results = process_sugarcane_images(image_paths)\n",
    "    \n",
    "    # Generar visualizaciones y análisis\n",
    "    density_map_fig, analysis_fig, distribution_fig, summary = visualize_large_sugarcane_analysis(results)\n",
    "    \n",
    "    # Mostrar las figuras (opcional, ya que también se guardan como archivos)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6547c9ff677a4788a19f5fcc33d79f8e",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Consistencia entre métodos de segmentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "27e98928b9d04dca85de7849356a4592",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Los resultados muestran que tanto el método K-Means como el método Otsu producen exactamente el mismo número de puntos clave para cada categoría (Damaged: 2628, Healthy: 3689, Mutilated: 3513). Esto sugiere una alta consistencia entre ambos algoritmos de segmentación cuando se aplican a estas imágenes específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dc4baa8cf66c4a6996b6f8f9e1f47a23",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Diferencias entre categoría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f71cca3902664c4db9e44f0aab5256e0",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- Las imágenes \"Healthy\" presentan la mayor cantidad de puntos clave (3689), lo que indica que tienen estructuras más complejas o detalladas.\n",
    "- Las imágenes \"Damaged\" tienen el menor número de puntos clave (2628), posiblemente porque el daño reduce la complejidad o ciertos detalles de la imagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b87f19cf0138454b89ed292da2e4bafd",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    " - Las imágenes \"Mutilated\" tienen un número intermedio de puntos clave (3513)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "40081d552f5a4bf6ae1ed8132a894605",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Dimensionalidad consistente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4690bc26696041cdaa24f56e86a9afae",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Todos los descriptores tienen la misma dimensionalidad (26 características por punto clave), lo que indica que se está utilizando el mismo algoritmo de extracción de características para todas las imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7bef67ef2b9940d185366120224b7b4d",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Densidad e intensidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bb657f99ba824e56b9435b195964a6d6",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- La categoría \"Healthy\" muestra la mayor densidad promedio (0.000920) y también la mayor intensidad promedio (0.4082).\n",
    "- La categoría \"Damaged\" tiene la menor densidad (0.000835) y la menor intensidad promedio (0.3426).\n",
    "- Esto podría sugerir que las imágenes saludables contienen más información distintiva por unidad de área."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "24e70b73040544c29e577a863344ecac",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Variación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "58d06747ad744be5b8294b0098f6e72b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Las imágenes \"Mutilated\" muestran la mayor variación promedio (0.1043), seguidas por \"Healthy\" (0.0827) y \"Damaged\" (0.0792). Esto indica que las características en imágenes mutiladas son más heterogéneas o variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "db18c495f26641849896e6b32ed6f020",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Estas estadísticas podrían ser útiles para entrenar un clasificador que distinga entre estas tres categorías, ya que muestran diferencias claras en la cantidad y distribución de puntos clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4ca19b05-25ab-4ed4-9f1b-6edc1d60a427' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "08992dd135ee496493550d7f50e23622",
  "deepnote_persisted_session": {
   "createdAt": "2025-02-26T00:16:37.217Z"
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
